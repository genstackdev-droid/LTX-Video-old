# LTX-Video ComfyUI Custom Node

[![HuggingFace](https://img.shields.io/badge/HuggingFace-Model-orange?logo=huggingface)](https://huggingface.co/Lightricks/LTX-Video)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![ComfyUI](https://img.shields.io/badge/ComfyUI-Custom%20Node-green)](https://github.com/comfyanonymous/ComfyUI)

**World-class, production-ready ComfyUI custom node** for LTX-Video text-to-video generation with hyper-realistic output, intelligent FPS handling (12-120 FPS), and professional-grade temporal consistency.

## ‚ú® Features

### Core Features ‚úÖ PRODUCTION READY
- **‚ú® Auto-Prompt Enhancement**: Transform basic prompts into professional cinematic results
- **üéûÔ∏è Intelligent FPS System (12-120 FPS)**: Advanced frame interpolation with 50-67% VRAM savings
- **üéØ Multi-Resolution Support**: 720p, 1080p, and 4K output with intelligent upscaling
- **‚ö° Smart Generation Strategy**: Generate at optimal base FPS, interpolate to target (up to 4x efficiency)
- **üîß Auto-Timestep Handling**: Automatically works with distilled and flexible checkpoints
- **üíæ Memory Optimized**: Generate 120 FPS videos on 24GB GPUs (normally requires 40GB+)
- **üì¶ Auto-Download**: Models download automatically from HuggingFace
- **üõ°Ô∏è Production-Grade Error Handling**: Comprehensive validation and helpful error messages
- **üìä Transparent Logging**: Complete visibility into generation process

### Advanced Features
- **üé¨ Text-to-Video Generation**: Create videos from text descriptions with professional quality
- **üé® Quality Modes**: Standard (fast) and Ultra (maximum quality) presets
- **üî¨ Advanced Interpolation**: Cosine interpolation for smoother motion than linear
- **‚è±Ô∏è Flexible Duration**: Generate 8-10 second videos (extensible)
- **üìà Intelligent Frame Calculation**: Automatic N*8+1 format compliance for VAE compatibility

### Coming Soon
- **üñºÔ∏è Image-to-Video**: Animate static images with motion
- **üìπ Multi-Keyframe Support**: Control video with multiple reference frames

## üöÄ Quick Installation

### Step 1: Clone Repository

```bash
cd ComfyUI/custom_nodes/
git clone https://github.com/genstackdev-droid/LTX-Video-old
```

### Step 2: Install Dependencies

```bash
cd LTX-Video-old
pip install -r requirements_comfyui.txt
```

### Step 3: Restart ComfyUI

Restart ComfyUI and look for "LTX-Video" nodes in the node browser.

## üì¶ Required Models

Models will automatically download on first use. Total size: ~18GB.

**üìñ [Complete Models Download Guide](MODELS.md)** - Detailed instructions for all download methods

| Model | Size | Install Path |
|-------|------|--------------|
| **LTX-Video Core** | ~13GB | `ComfyUI/models/checkpoints/` |
| **Text Encoder (T5-XXL)** | ~4.7GB | `ComfyUI/models/clip/` |
| **VAE** | ~335MB | `ComfyUI/models/vae/` |

### Automatic Download

Models will download automatically when you first use the node. If you want to download them manually:

```bash
# Method 1: Using the downloader script (from ComfyUI root or custom_nodes/LTX-Video-old)
python -c "from model_downloader import download_all_models; download_all_models()"

# Method 2: Using huggingface-cli
cd /ComfyUI/models

# Download LTX-Video core model
huggingface-cli download Lightricks/LTX-Video ltxv-13b-0.9.8-distilled.safetensors --local-dir checkpoints/

# Download Text Encoder
huggingface-cli download Lightricks/LTX-Video text_encoders/t5-v1_1-xxl-fp16.safetensors --local-dir clip/

# Download VAE
huggingface-cli download stabilityai/sd-vae-ft-mse-original vae-ft-mse-840000-ema-pruned.safetensors --local-dir vae/
```

### Manual Download (Alternative)

If automatic download fails, download manually from HuggingFace:

1. **LTX-Video Core Model** (~13GB)
   - URL: https://huggingface.co/Lightricks/LTX-Video/resolve/main/ltxv-13b-0.9.8-distilled.safetensors
   - Save to: `ComfyUI/models/checkpoints/ltx-video-13b-v0.9.7-distilled.safetensors`

2. **Text Encoder** (~4.7GB)
   - URL: https://huggingface.co/Lightricks/LTX-Video/resolve/main/text_encoders/t5-v1_1-xxl-fp16.safetensors
   - Save to: `ComfyUI/models/clip/t5-v1_1-xxl-fp16.safetensors`

3. **VAE** (~335MB)
   - URL: https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors
   - Save to: `ComfyUI/models/vae/vae-ft-mse-840000-ema-pruned.safetensors`

## üíª System Requirements

### Minimum
- **GPU**: NVIDIA RTX 3060 (12GB VRAM)
- **RAM**: 16GB
- **Storage**: 20GB free space
- **OS**: Windows 10/11, Linux, macOS

### Recommended
- **GPU**: NVIDIA RTX 4070 Ti (16GB VRAM) or better
- **RAM**: 32GB
- **Storage**: 50GB SSD

### Optimal
- **GPU**: NVIDIA RTX 4090 (24GB VRAM) or A6000
- **RAM**: 64GB
- **Storage**: 100GB SSD

## üéØ Usage

### Basic Text-to-Video

1. Add "LTX-Video Full Pipeline" node to your workflow
2. Enter your prompt: e.g., "A serene lake at sunset"
3. Select duration (8s or 10s) and resolution (720p/1080p/4K)
4. Click "Queue Prompt"

### Example Prompts

**Basic (Auto-Enhanced)**:
```
"a cat walking in a garden"
```

**Detailed**:
```
"A cinematic walk through a misty forest at dawn, volumetric fog filtering golden sunlight through ancient trees, smooth camera dolly forward, photorealistic, 8k quality"
```

## üìã Available Nodes

1. **LTX-Video Full Pipeline** - Complete text-to-video generation
2. **LTX-Video Prompt Enhancer** - Automatic prompt improvement
3. **LTX-Video Frame Interpolator** - Extend video duration
4. **LTX-Video 4K Upscaler** - Intelligent resolution upscaling
5. **LTX-Video Advanced Sampler** - Fine-grained generation control

## üé® Pre-Built Workflows

Ready-to-use workflow files in the `workflows/` directory:

### 1. **ltx_simple_quickstart.json** ‚≠ê RECOMMENDED FOR BEGINNERS
**Perfect for first-time users!**
- ‚úÖ Minimal setup - just enter prompt and click Queue
- ‚úÖ All nodes pre-connected and ready
- ‚úÖ Includes helpful documentation in the workflow
- **Nodes**: Prompt Enhancer ‚Üí Full Pipeline ‚Üí Video Output
- **Quality**: Standard (1080p, 80 steps)
- **Speed**: Fast generation (~2-3 minutes on RTX 4090)

### 2. **ltx_unified_production.json**
**Professional production workflow**
- ‚úÖ Fixed and fully connected (November 2024)
- ‚úÖ Prompt enhancer properly linked
- Ultra quality mode with 4K output
- 120 steps for maximum detail
- **Nodes**: Prompt Enhancer ‚Üí Full Pipeline ‚Üí Video Output
- **Quality**: Ultra (4K, 120 steps)
- **Speed**: Slower but highest quality (~4-5 minutes on H100)

### 3. **ltx_advanced_modular.json**
**Complete modular pipeline**
- ‚úÖ All enhancement nodes connected
- Frame interpolation for extended duration
- 4K upscaling with tiled processing
- Full post-processing pipeline
- **Nodes**: Prompt Enhancer ‚Üí Full Pipeline ‚Üí Interpolator ‚Üí Upscaler ‚Üí Video Output
- **Quality**: High (1080p‚Üí4K upscaled, 80 steps)
- **Speed**: Moderate (~3-4 minutes on RTX 4090)

### How to Load Workflows

In ComfyUI:
1. Click the **"Load"** button (folder icon)
2. Navigate to `custom_nodes/LTX-Video-old/workflows/`
3. Select any workflow JSON file
4. **Edit the prompt** in the Prompt Enhancer node
5. Click **"Queue Prompt"** to generate!

All workflows include:
- ‚úÖ Model selection (HuggingFace path configurable)
- ‚úÖ Sampler selection (DPM++ 3M SDE Karras default)
- ‚úÖ All nodes properly connected
- ‚úÖ Built-in documentation notes
- ‚úÖ Optimized for November 2024 / 2025 standards

## üõ†Ô∏è Troubleshooting

### Node Not Appearing
- Ensure you installed dependencies: `pip install -r requirements_comfyui.txt`
- Restart ComfyUI completely
- Check ComfyUI console for error messages

### Out of Memory Errors
- Reduce resolution (use 720p instead of 1080p/4K)
- Reduce number of inference steps
- Close other GPU applications

### Models Not Loading
- Verify models are in correct directories
- Check file names match exactly
- Try manual download if auto-download fails

## üìö Additional Documentation

- [Installation Guide](docs/INSTALL.md) - Detailed installation instructions
- [Quick Reference](docs/QUICK_REFERENCE.md) - Node parameters and workflows
- [FPS Configuration Guide](docs/FPS_GUIDE.md) - Adjustable frame rate (12-120 FPS) usage and best practices
- [ComfyUI Documentation](docs/README_COMFYUI.md) - Complete ComfyUI integration guide
- [Workflows](workflows/) - Example workflow JSON files
- [Original README](README_ORIGINAL.md) - LTX-Video project information

## üîó Links

- [LTX-Video Official Website](https://ltx.video)
- [HuggingFace Model](https://huggingface.co/Lightricks/LTX-Video)
- [Research Paper](https://arxiv.org/abs/2501.00103)
- [ComfyUI](https://github.com/comfyanonymous/ComfyUI)

## üé¨ Complete Setup Summary

Here's the complete setup in one go:

```bash
# 1. Clone the repository into ComfyUI custom_nodes
cd ComfyUI/custom_nodes/
git clone https://github.com/genstackdev-droid/LTX-Video-old
cd LTX-Video-old

# 2. Install dependencies
pip install -r requirements_comfyui.txt

# 3. Download models (automatic)
python -c "from model_downloader import download_all_models; download_all_models()"

# 4. Restart ComfyUI and start generating!
```

**Or** let models auto-download on first use - just skip step 3 and use the node!

## üìÑ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgements

- LTX-Video by Lightricks
- ComfyUI by comfyanonymous
- Based on state-of-the-art research in video generation

## üìû Support

- Open an issue on GitHub for bugs or feature requests
- Check existing issues for solutions to common problems
- Join the [LTX Discord](https://discord.gg/ltxplatform) for community support
